{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510bcd22",
   "metadata": {},
   "source": [
    "**Name: Andrew Chang**\n",
    "\n",
    "**email: andrewjych@gmail.com**\n",
    "\n",
    "**For: Affinity Solutions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416001ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies for part 1\n",
    "import re\n",
    "\n",
    "# dependencies for part 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# dependencies for part 3\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cec05",
   "metadata": {},
   "source": [
    "# Store Number Entity Extraction\n",
    "\n",
    "## General Layout of This Notebook\n",
    "\n",
    "I will be laying out all of my proposed methods, and the experiments I performed with them. **Note: I put down my thought process and my workflow here, if you are interested in final results, please go to the Section 4.x (page 23-36).**\n",
    "\n",
    "As a simpler example of entity extraction, we will attempt to **extract the store numbers out of a corpus containing a business/organization and a specific store number**. We will attempt 3 methods of extracting the store number in this notebook:\n",
    "\n",
    "1) Use regular expressions and don't use machine learning\n",
    "\n",
    "2) Build an RNN-based classifier, in TensorFlow, to predict the store number\n",
    "\n",
    "3) Use a multi-stage entity extraction model, from spaCy, to predict the correct entity, and extract it\n",
    "\n",
    "We will discuss the background of each method, and the pros and cons of each.\n",
    "\n",
    "# 1) Regex Parsing\n",
    "\n",
    "Although the end goal of this notebook is to show that inferencing with a machine learning model can do this entity extraction task, it is good to explore non-ML options before we pursue any statistical methods.\n",
    "\n",
    "**Regular Expressions** are a good first choice whenever we have to do some formatting of alphanumerical strings. We can identify a few cases that we see in our data, and we can appropriately filter out what we see as \"store numbers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c80391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\Chang\\Desktop\\Work Things\\Internships\\Affinity Solutions\\Summer Internship - Homework Exercise.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76708250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(s):\n",
    "    return re.sub(' +', ' ', s)\n",
    "\n",
    "# split on punctuations because the vectorizer will not understand any number with it\n",
    "def split_punc(s):\n",
    "    return re.sub(r'([^\\w\\s]|_)',' ',s)\n",
    "\n",
    "def split_leading_zeros(s):\n",
    "    return re.sub(r'\\b0+', '', s)\n",
    "\n",
    "# split numbers from words\n",
    "\n",
    "def split_num_from_word(s):\n",
    "    li_split = s.split(' ')\n",
    "    li_where_to_split = []\n",
    "    start_, end_ = 0, 0\n",
    "    for ind, item in enumerate(li_split):\n",
    "        # filter out for words with both letters and numbers\n",
    "        if not item.isalpha() and item.isalnum():\n",
    "            split_num_word = re.split('(\\d+)', item)\n",
    "            if len(split_num_word[-1]) > 2 or len(split_num_word[0]) > 2:\n",
    "                start_, end_ = (s.index(split_num_word[1])), s.index(split_num_word[1]) + len(split_num_word[1])\n",
    "\n",
    "    return s[:start_] + ' ' + s[start_:end_] + ' ' + s[end_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d0fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_descriptor = data['transaction_descriptor']\n",
    "\n",
    "data['transaction_descriptor'] = list(map(clean_spaces, map(split_leading_zeros, map(split_num_from_word, map(split_punc, transaction_descriptor)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fafd20",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' DOLRTREE 2257 22574 ROSWELL', '2257'),\n",
       " (' AUTOZONE 3547', '3547'),\n",
       " (' TGI FRIDAYS 1485 ', '1485'),\n",
       " (' BUFFALO WILD WINGS 3', '3'),\n",
       " (' J CREW 568 ', '568'),\n",
       " (' KRISPY KREME 40 GREENVILLE SC', '40'),\n",
       " (' FIVE GUYS MN 1847 ECOM 612 339 9733 MN', '1847'),\n",
       " (' CASEYS GEN STORE 2650', '2650'),\n",
       " (' HUDDLE HOUSE 535', '535'),\n",
       " (' JAMBA JUICE 1305', '1305'),\n",
       " (' ANN TAYLOR FACTORY 2202', '2202'),\n",
       " (' Subway 26824', '26824'),\n",
       " (' MARSHALLS 688', '688'),\n",
       " (' OREILLY AUTO 4681', '4681'),\n",
       " (' TA 227 BARSTOW REST', '227'),\n",
       " (' SONIC 3207', '3207'),\n",
       " (' HY VEE 1040', '1040'),\n",
       " (' MCDONALD S F1013', 'F1013'),\n",
       " (' CHEVRON 207812', '207812'),\n",
       " (' EXPRESS 920', '920'),\n",
       " (' MCDONALD S F16829', 'F16829'),\n",
       " (' CHEVRON 208998 Q61', '208998'),\n",
       " (' STARBUCKS STORE 49134', '49134'),\n",
       " (' CHEVRON 302900', '302900'),\n",
       " (' CIRCLE K 1251', '1251'),\n",
       " (' NST BEST BUY 479 2610', '479'),\n",
       " (' HOLIDAY STNSTORE 354', '354'),\n",
       " (' DOMINO S 7430', '7430'),\n",
       " (' NST ROSS STORE 483280353', '483280353'),\n",
       " (' MCDONALD S F5579', 'F5579'),\n",
       " (' NST ROSS STORES 10262660', '10262660'),\n",
       " (' HOLIDAY STNSTORE 447', '447'),\n",
       " (' NST BEST BUY 25 232381', '25'),\n",
       " (' MEIJER 196', '196'),\n",
       " (' SUBWAY 516260', '516260'),\n",
       " (' DOMINO S 6870', '6870'),\n",
       " ('MARATHON PETRO 45518 ', '45518'),\n",
       " (' MCDONALD S F2128', 'F2128'),\n",
       " (' DOLLAR GENERAL 22357', '22357'),\n",
       " (' SUNOCO 748361300', '748361300'),\n",
       " (' MCDONALD S F3172', 'F3172'),\n",
       " (' DENNY S 9505', '9505'),\n",
       " (' THE HOME DEPOT 1407', '1407'),\n",
       " (' PAPA JOHN S 1548 COM', '1548'),\n",
       " (' CIRCLE K 6524 OCALA FL', '6524'),\n",
       " (' AutoZone 6425 711 E MAI', '6425'),\n",
       " (' THE HOME DEPOT 6853', '6853'),\n",
       " (' TEXACO 308296', '308296'),\n",
       " (' NNT LANE BRYANT 455460', '5546'),\n",
       " (' HOLIDAY STNSTORE 142', '142'),\n",
       " (' NST ROSS STORES 11572299', '11572299'),\n",
       " (' DOMINO S 3857', '3857'),\n",
       " (' WEST MARINE 1327', '1327'),\n",
       " (' NST BEST BUY 27 2732', '27'),\n",
       " (' HOLIDAY STNSTORE 303', '303'),\n",
       " (' PALAIS ROYAL 24', '24'),\n",
       " (' MEIJER 209 128', '209'),\n",
       " (' DENNY S 7350 180073', '7350'),\n",
       " (' NST BEST BUY 1783 532412', '1783'),\n",
       " (' WAL MART 1316', '1316'),\n",
       " (' WALGREENS 4102', '4102'),\n",
       " (' NST ROSS STORES 11002986', '11002986'),\n",
       " (' CNS EXPRESS 98 670753', '98'),\n",
       " (' NST BEST BUY 1774 532399', '1774'),\n",
       " (' CIRCLE K 2910', '2910'),\n",
       " (' NNT SEARS HOMETOWN 231594', '2315'),\n",
       " (' NST ROSS STORES 10630845', '10630845'),\n",
       " (' DAIRY QUEEN 42', '42'),\n",
       " (' HOLIDAY STNSTORE 437', '437'),\n",
       " ('NNT FAMOUS FOOTWEAR 572264 ', '572264'),\n",
       " ('NNT BURLNGTON STORE 171793 ', '171793'),\n",
       " (' SUBWAY 3312162', '3312162'),\n",
       " (' JIMMY JOHNS 4 ECO', '4'),\n",
       " (' CVS PHARMACY 1858 ', '1858'),\n",
       " (' MCDONALD S F26490', 'F26490'),\n",
       " (' JIMMY JOHNS 974', '974'),\n",
       " ('NNT FAMOUS FOOTWEAR 881706 ', '881706'),\n",
       " (' WENDY S 3626', '3626'),\n",
       " (' CIRCLE K 6286', '6286'),\n",
       " (' BIG O TIRES 6255 GRAND JUNCTIOCO', '6255'),\n",
       " (' NST ROSS STORES 14560807', '14560807'),\n",
       " (' TACO BELL 739723', '739723'),\n",
       " (' BOSTON MARKET 113', '113'),\n",
       " (' NST ROSS STORES 14782798', '14782798'),\n",
       " (' SUBWAY 25139 FORT MOJAVE AZ', '25139'),\n",
       " (' DENNY S 9386', '9386'),\n",
       " (' NST ROSS STORES 12862950', '12862950'),\n",
       " (' ARBYS 7591 CAMBRIDGE', '7591'),\n",
       " (' CASEYS GEN STORE 2', '2'),\n",
       " (' NST BEST BUY 500 970304', '500'),\n",
       " ('MCDONALD S F 35869 MCDONALD S F35869', 'F35869'),\n",
       " ('NNT FAMOUS FOOTWEAR 470811 ', '470811'),\n",
       " (' SUNOCO 374572602', '374572602'),\n",
       " (' DOMINO S 9502', '9502'),\n",
       " (' KFC G020029', 'G020029'),\n",
       " (' DUNKIN 355514', '355514'),\n",
       " (' THE HOME DEPOT 6828', '6828'),\n",
       " ('RUE 21 1129 BLUE', '1129'),\n",
       " (' WM SUPERCENTER 34', '34'),\n",
       " ('RACETRAC 485 4853', '485'),\n",
       " (' DEL TACO 833', '833'),\n",
       " ('NNT BURLNGTON STORE 472605 ', '472605'),\n",
       " (' WENDY S 5320', '5320'),\n",
       " (' DUNKIN 337734 Q35', '337734'),\n",
       " (' MCDONALD S F565 CLARKSVILLE TN', 'F565'),\n",
       " (' WALGREENS 13822', '13822'),\n",
       " (' QDOBA 2050', '2050'),\n",
       " (' TACO BELL 729724', '729724'),\n",
       " (' THE HOME DEPOT 662', '662'),\n",
       " (' HOLIDAY STNSTORE 453', '453'),\n",
       " (' NST BEST BUY 235 860244', '235'),\n",
       " (' WENDY S 4215', '4215'),\n",
       " (' NST ROSS STORES 13360692', '13360692'),\n",
       " (' NNT FAMOUSFOOTWEAR 570903', '570903'),\n",
       " (' NST BEST BUY 304 561499', '304'),\n",
       " (' NST BEST BUY 380 830230', '380'),\n",
       " (' HOLIDAY STNSTORE 46', '46'),\n",
       " (' REGIS SALON 4842', '4842'),\n",
       " (' NNT ZUMIEZ 409 581936', '409'),\n",
       " ('PIER 1 IMPORTS 8060 ', '806'),\n",
       " (' LOWES 2282 BRANDON FL 7679 ', '2282'),\n",
       " (' WALGREENS 15474', '15474'),\n",
       " (' STARBUCKS 8988 MEDFORD', '8988'),\n",
       " (' WENDYS 179', '179'),\n",
       " (' ARBYS 7871 THIEF RIVER', '7871'),\n",
       " (' NST BEST BUY 387 181855', '387'),\n",
       " (' WENDY S 1970 1970', '1970'),\n",
       " (' HOLIDAY STNSTORE 256', '256'),\n",
       " (' PAPA JOHN S 295', '295'),\n",
       " (' WENDYS 514 TAMPA FL 7271 ', '514'),\n",
       " ('MURPHY 7548 ATWALMART LITHIA SPRINGGA', '7548'),\n",
       " ('NNT FAMOUS FOOTWEAR 830366 ', '830366'),\n",
       " (' QDOBA 291 FORT COLLINS COUS', '291'),\n",
       " (' JUSTICE 407', '407'),\n",
       " ('NNT BURLNGTON STORE 1491 ', '1491'),\n",
       " (' NNT HIBBETT SPORTS 72473', '72473'),\n",
       " (' HARBOR FREIGHT TOOLS 233', '233'),\n",
       " (' MCDONALD S F6297', 'F6297'),\n",
       " (' ARBY S 8396', '8396'),\n",
       " (' TACO BELL 723832', '723832'),\n",
       " ('NNT BURLNGTON STORE 460391 ', '460391'),\n",
       " (' JIMMY JOHNS 13', '13'),\n",
       " (' IN N OUT BURGER 284', '284'),\n",
       " (' THE CHILDRENS PLACE 1624', '1624'),\n",
       " (' SPEEDWAY 6406 BRADENTO FL 5243 ', '6406'),\n",
       " (' BELK 619 PHIPP', '619'),\n",
       " (' NNT SEARS HOMETOWN 415', '4'),\n",
       " (' NST BEST BUY 47 571045', '47'),\n",
       " (' SUNOCO 780350500 QPS', '780350500'),\n",
       " (' STOP SHOP 523', '523'),\n",
       " (' KUM GO 927', '927'),\n",
       " (' KROGER 445', '445'),\n",
       " (' PAPA MURPHY S CA142', 'CA142'),\n",
       " (' AUTOZONE 2322 1', '2322'),\n",
       " (' LOAF N JUG 167', '167'),\n",
       " (' KFC L765004 66850041', 'L765004'),\n",
       " (' DAIRY QUEEN 11789', '11789'),\n",
       " (' SUPERAMERICA 4204', '4204'),\n",
       " (' Subway 14639', '14639'),\n",
       " (' CHECKERS 687', '687'),\n",
       " ('OCHARLEYS 206 BOWLGR ', '206'),\n",
       " (' JIMMY JOHNS 1338', '1338'),\n",
       " (' FRESH EASY 1167 CORONA CA', '1167'),\n",
       " (' DOMINO S 3162', '3162'),\n",
       " (' PIZZA HUT 2989', '2989'),\n",
       " (' DUNKIN 346432 Q35', '346432'),\n",
       " (' SUNOCO 13625903', '13625903'),\n",
       " (' SUBWAY 40055', '4005'),\n",
       " (' SUBWAY 4016168', '4016168'),\n",
       " (' TJMAXX 452 452', '452'),\n",
       " (' WENDY S 4611', '4611'),\n",
       " (' WINN DIXIE 1', '1'),\n",
       " (' ROSS STORES 1049', '1049'),\n",
       " (' DOMINO S 1901', '1901'),\n",
       " (' JO ANN STORE 2314', '2314'),\n",
       " (' TACO BELL 29071', '29071'),\n",
       " (' OLD NAVY 6470', '6470'),\n",
       " (' KOHLS 43 3737 S 27TH', '43'),\n",
       " (' LOWE S 46', '46'),\n",
       " (' MEIJER 29 233', '29'),\n",
       " (' JIMMY JOHNS 2', '2'),\n",
       " (' MACY S 730', '730'),\n",
       " (' NST BEST BUY 421 131953', '421'),\n",
       " (' THE HOME DEPOT 1085', '1085'),\n",
       " (' CIRCLE K 23853', '23853'),\n",
       " (' SIX 2 46221 SIX 2 46221', '46221'),\n",
       " (' AUTOZONE 1563', '1563'),\n",
       " (' CIRCLE K 5601', '5601'),\n",
       " (' NST BEST BUY 29 871122', '29'),\n",
       " (' WAL MART 5754 WILLIAMSBURG VA', '5754'),\n",
       " (' TACO BELL 21103', '21103'),\n",
       " (' NST ROSS STORES 17131522', '17131522'),\n",
       " (' NST BEST BUY 440 130975', '440'),\n",
       " ('WAL MART 976 WINNSBORO LA', '976'),\n",
       " (' BP 5998869CK ST', '5998869'),\n",
       " (' ROSS STORES 15', '15'),\n",
       " (' SPRINT STORE 346', '346'),\n",
       " (' SPEEDWAY 7134 4343 OL', '7134'),\n",
       " (' THE HOME DEPOT 8550', '8550'),\n",
       " (' OUTBACK 315', '315'),\n",
       " (' IN N OUT BURGER 242', '242'),\n",
       " ('BP 9442088 LIBERTYVILLE B', '9442088'),\n",
       " (' JCPENNEY 1419', '1419'),\n",
       " (' ROSS STORES 1019', '1019'),\n",
       " (' WM SUPERCENTER 38', '38'),\n",
       " (' TUESDAY MORNING 673 6', '673'),\n",
       " (' IHOP 629 WHITE HOUSE TN', '629'),\n",
       " (' LBOUTLETS 4249 1475 N BUR', '4249'),\n",
       " (' WINN DIXIE 2505 VALRICO FL 3454 ', '2505'),\n",
       " (' BURLINGTON STORES 825', '825'),\n",
       " (' WM SUPERCENTER 2923', '2923'),\n",
       " (' BUFFALO WILD WINGS 58 CARSON CITY NV', '58'),\n",
       " (' BOB EVANS REST 2039', '2039'),\n",
       " (' JIMMY JOHNS 382 E', '382'),\n",
       " (' PENSKE TRK LSG 12260', '12260'),\n",
       " (' AEROPOSTALE 864', '864'),\n",
       " (' GIANT 338', '338'),\n",
       " (' DOLLAR GENERAL DG 11', '11'),\n",
       " (' NNT ITS FASHION 70360265', '70360265'),\n",
       " (' BIG LOTS STORES 4393 ', '4393'),\n",
       " (' AT T SPRING MOBILE 62', '62'),\n",
       " (' OLD NAVY US 7212', '7212'),\n",
       " (' BP 8644346ES 30 B96', '8644346'),\n",
       " ('NNT POLO RL WRENTHA 130571 ', '13057'),\n",
       " (' CHAMPS 14178', '14178'),\n",
       " (' CNS GUESS 3220 282163', '3220'),\n",
       " (' HOMEGOODS 407', '407'),\n",
       " (' DOLLAR GENERAL 14', '14'),\n",
       " (' WINN DIXIE 2454 SEFFNER FL 1033 ', '2454'),\n",
       " (' NST ROSS STORES 17871401', '17871401'),\n",
       " (' KANGAROO EXPRESS 3192 SILER CITY NC', '3192'),\n",
       " (' NNT SEARS HOMETOWN 862751', '8627'),\n",
       " (' KANGAROO EXP 1', '1'),\n",
       " (' NAVY EXCHANGE 50161 3', '50161'),\n",
       " (' KANGAROO EXPRESS 3889', '3889'),\n",
       " (' NST BEST BUY 401 731468', '401'),\n",
       " (' CASEYS GEN STORE 2597 SLOAN IA51055', '2597'),\n",
       " (' PAPA JOHN S 1253', '1253'),\n",
       " (' NST BEST BUY 507 762589', '507'),\n",
       " (' NST ROSS STORE 472831773', '472831773'),\n",
       " (' NST BEST BUY 277 661145', '277'),\n",
       " (' NST BEST BUY 59 60251', '59'),\n",
       " (' NST BEST BUY 48 72393', '48'),\n",
       " (' NST BEST BUY 231 160037', '231'),\n",
       " (' WALGREENS 11332', '11332'),\n",
       " (' NST ROSS STORES 16482149', '16482149'),\n",
       " (' MCDONALD S F33735', 'F33735'),\n",
       " (' MCDONALD S F671', 'F671'),\n",
       " (' MCDONALD S F11370 ', 'F11370'),\n",
       " (' WM SUPERCENTER 50', '50'),\n",
       " (' BURGER KING 11820 Q07', '11820'),\n",
       " (' DENNY S 6619 ON', '6619'),\n",
       " (' DOMINO S 6102', '6102'),\n",
       " (' MCDONALD S F2383 972 231 3337 TX', 'F2383'),\n",
       " (' TACO BELL 733780', '733780'),\n",
       " (' NST ROSS STORES 62132001', '62132001'),\n",
       " (' MCDONALD S F33124', 'F33124'),\n",
       " (' WALGREENS 15392', '15392'),\n",
       " (' NNT HIBBETT SPORTS 860977', '860977'),\n",
       " (' MCDONALD S F122', 'F122'),\n",
       " (' PAPA JOHN S 982', '982'),\n",
       " (' NST BEST BUY 188 871025', '188'),\n",
       " (' TACO BELL 15843', '15843'),\n",
       " (' CIRCLE K 2742643', '2742643'),\n",
       " ('NNT FAMOUS FOOTWEAR 1261 ', '1261'),\n",
       " (' EXPRESS 813', '813'),\n",
       " (' BURGER KING 7414', '7414'),\n",
       " (' SUNOCO 39962380', '39962380'),\n",
       " (' NST BEST BUY 392 80590', '392'),\n",
       " (' ARCO 66165', '66165'),\n",
       " (' WAL MART 647', '647'),\n",
       " (' H R BLOCK 14788', '14788'),\n",
       " (' FOOTACTION 57331 TAMPA FL 2340 ', '57331'),\n",
       " (' 7 ELEVEN 34493', '34493'),\n",
       " (' HOLIDAY STNSTORE 408', '408'),\n",
       " (' STARBUCKS 10101', '10101'),\n",
       " (' SUNOCO 837208800 STATEN ISLANDNY', '837208800'),\n",
       " (' NST BEST BUY 405 562536', '405'),\n",
       " (' PANERA BREAD 601128', '601128'),\n",
       " (' BURGER KING 4633 Q07', '4633'),\n",
       " (' WAL MART 1997', '1997'),\n",
       " (' NST ROSS STORES 21000236', '21000236'),\n",
       " ('NNT FAMOUS FOOTWEAR 730376 ', '730376'),\n",
       " ('MARATHON PETRO 170928 MIAMI', '170928'),\n",
       " (' SUNOCO 104235700 QPS', '104235700'),\n",
       " (' NNT FAMOUSFOOTWEAR 132427', '132427'),\n",
       " (' STARBUCKS STORE 11966', '11966'),\n",
       " (' SUBWAY 3317963', '3317963'),\n",
       " (' NST BEST BUY 401 948', '401'),\n",
       " (' NST BEST BUY 51 672842', '51'),\n",
       " (' PAPA MURPHY S UT044 OLO', 'UT044'),\n",
       " ('BP 1003300 DANADA SQUS', '1003300'),\n",
       " (' SUBWAY 32128', '3212'),\n",
       " (' TEXACO 303733', '303733'),\n",
       " (' THE BUCKLE 513', '513'),\n",
       " (' MCDONALD S F2151', 'F2151'),\n",
       " (' NST BEST BUY 1403 332411', '1403'),\n",
       " (' CVS PHARMACY 6689', '6689'),\n",
       " (' BANANA REPUBLIC 8109', '8109'),\n",
       " (' BOSTON MARKET 443', '443')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all descriptors and store numbers\n",
    "\n",
    "list(zip(data['transaction_descriptor'], data['store_number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb7fb8",
   "metadata": {},
   "source": [
    "We see that regular expressions have allowed us to clean the descriptors up a lot. However, we must discuss why this is not a scalable, nor flexible solution for our task:\n",
    "\n",
    "## Pros of Regular Expressions/Non-ML Methods in This Task\n",
    "\n",
    "- Extremely simple implementation, regular expressions are quite literally one-liners, and their effect is profound\n",
    "- We do not have to train, and tune a model; this is a big deal because training models (especially production-worthy models) is time-intensive, and even resource-heavy depending on the scale of the task\n",
    "\n",
    "## Cons of Regular Expressions/Non-ML Methods in This Task\n",
    "\n",
    "- This is too rigid; regular expressions are rigid queries, and they handle only a specific subset of all the formatting cases that could arise in this type of task.\n",
    "- Not scalable, this is similar to before, but if we had a dataset that wasn't 300, but 300k, maybe even more, filtering with typical string methods and regular expressions would surely fail.\n",
    "\n",
    "**Note: Hardcoding rules based on \"testing\" data is also not good practice in a data science/machine learning workflow, so this would not be something that we pursue in that context anyways.**\n",
    "\n",
    "# 2) Recurrent Neural Network-Based Model\n",
    "\n",
    "**Classify Tag of Data** $\\rightarrow$ **Attach Classification to Each Token** $\\rightarrow$ **Extract Only Tokens with tags that have \"Store Number\" Class**\n",
    "\n",
    "This will require us to train an entity recognition model in the first part, and then do significant post-processing to obtain the result that we want.\n",
    "\n",
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f335c",
   "metadata": {},
   "source": [
    "**Clean the descriptors using regular expressions**. There are a lot of numbers that are not recoverable because of weird formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5bd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\Chang\\Desktop\\Work Things\\Internships\\Affinity Solutions\\Summer Internship - Homework Exercise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d9f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(s):\n",
    "    return re.sub(' +', ' ', s)\n",
    "\n",
    "# split on punctuations because the vectorizer will not understand any number with it\n",
    "def split_punc(s):\n",
    "    return re.sub(r'([^\\w\\s]|_)',' ',s)\n",
    "\n",
    "def split_leading_zeros(s):\n",
    "    return re.sub(r'\\b0+', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7560ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_descriptor = df1['transaction_descriptor']\n",
    "\n",
    "df1['transaction_descriptor'] = list(map(clean_spaces, map(split_leading_zeros, map(split_punc, transaction_descriptor))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5cea1",
   "metadata": {},
   "source": [
    "## Make a New DataFrame with Inputs Split by Token\n",
    "\n",
    "We will make sure to preserve which entry it was, and to preserve the tokens themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e881cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      DOLRTREE\n",
       "0          2257\n",
       "0         22574\n",
       "0       ROSWELL\n",
       "1      AUTOZONE\n",
       "         ...   \n",
       "298    REPUBLIC\n",
       "298        8109\n",
       "299      BOSTON\n",
       "299      MARKET\n",
       "299         443\n",
       "Name: transaction_descriptor, Length: 1057, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['transaction_descriptor'].str.split(' ').explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeca9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn = pd.DataFrame(data={})\n",
    "\n",
    "df_nn['Tokens'] = df1['transaction_descriptor'].str.split(' ').explode()\n",
    "\n",
    "df_nn['Descriptor #'] = df_nn.index + 1\n",
    "\n",
    "df1 = df_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f6137",
   "metadata": {},
   "source": [
    "### Method\n",
    "\n",
    "The classes we will make here are **word vs number**. Our plan is to tag anything that seems like a number as numbers. This will help accomplish the task (in theory) because we will be splitting every descriptor token-by-token, and, in a perfect circumstance, it the model would only flag the store number as a \"number\", and the rest of the tokens as \"not a number\".\n",
    "\n",
    "Once we have deduced which descriptors have a \"number\" or a \"word\", we can further filter out which \"numbers\" are actually store numbers, and which ones are not. Because we have preserved the index, we can easily recover whether each token instance corresponds to a train/test/val and which store number it corresponds to.\n",
    "\n",
    "We will now tag this data using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33cced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if string has either letters, numbers, or has both\n",
    "# if string has only letters, then it is just going to be labeled \"Text\"\n",
    "# if a string has only numbers or both letters and numbers, it is going to be labeled \"Numeric\"\n",
    "\n",
    "def check_string(arr_strings):\n",
    "    li_tag = []\n",
    "    for s in arr_strings:\n",
    "        if (s.isalnum() and not s.isalpha() and not s.isdigit()) or s.isdigit():\n",
    "            li_tag.append('Numeric')\n",
    "        else:\n",
    "            li_tag.append('Text')\n",
    "            \n",
    "    return li_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0eec43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Descriptor #</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOLRTREE</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2257</td>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22574</td>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSWELL</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTOZONE</td>\n",
       "      <td>2</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>REPUBLIC</td>\n",
       "      <td>299</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>8109</td>\n",
       "      <td>299</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>300</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>MARKET</td>\n",
       "      <td>300</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>443</td>\n",
       "      <td>300</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens  Descriptor #      Tag\n",
       "0    DOLRTREE             1     Text\n",
       "0        2257             1  Numeric\n",
       "0       22574             1  Numeric\n",
       "0     ROSWELL             1     Text\n",
       "1    AUTOZONE             2     Text\n",
       "..        ...           ...      ...\n",
       "298  REPUBLIC           299     Text\n",
       "298      8109           299  Numeric\n",
       "299    BOSTON           300     Text\n",
       "299    MARKET           300     Text\n",
       "299       443           300  Numeric\n",
       "\n",
       "[1057 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Tag'] = check_string(df1['Tokens'])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5530b",
   "metadata": {},
   "source": [
    "## Start Vectorizing Text\n",
    "\n",
    "We will start the process of vectorizing here. We will do the vectorization manually, as this is roughly equivalent to what TensorFlow's TextVectorization layer does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db7e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a mapping of numerical id's to words and tags\n",
    "\n",
    "def dict_map(data, token):\n",
    "    token_id = dict()\n",
    "    id_token = dict()\n",
    "    \n",
    "    if token == 'Tokens':\n",
    "        vocab = list(data['Tokens'].unique())\n",
    "    else:\n",
    "        vocab = list(data['Tag'].unique())\n",
    "    \n",
    "    id_token = {ide: tok for ide, tok in enumerate(vocab)}\n",
    "    token_id = {tok: ide for ide, tok in enumerate(vocab)}\n",
    "    \n",
    "    return token_id, id_token\n",
    "\n",
    "word_to_id, id_to_word = dict_map(df1, 'Tokens')\n",
    "\n",
    "tag_to_id, id_to_tag = dict_map(df1, 'Tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c4a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 0, 'Numeric': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ec3157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Descriptor #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Tag ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOLRTREE</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2257</td>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22574</td>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSWELL</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTOZONE</td>\n",
       "      <td>2</td>\n",
       "      <td>Text</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>REPUBLIC</td>\n",
       "      <td>299</td>\n",
       "      <td>Text</td>\n",
       "      <td>599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>8109</td>\n",
       "      <td>299</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>BOSTON</td>\n",
       "      <td>300</td>\n",
       "      <td>Text</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>MARKET</td>\n",
       "      <td>300</td>\n",
       "      <td>Text</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>443</td>\n",
       "      <td>300</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens  Descriptor #      Tag  Token ID  Tag ID\n",
       "0    DOLRTREE             1     Text         0       0\n",
       "0        2257             1  Numeric         1       1\n",
       "0       22574             1  Numeric         2       1\n",
       "0     ROSWELL             1     Text         3       0\n",
       "1    AUTOZONE             2     Text         4       0\n",
       "..        ...           ...      ...       ...     ...\n",
       "298  REPUBLIC           299     Text       599       0\n",
       "298      8109           299  Numeric       600       1\n",
       "299    BOSTON           300     Text       199       0\n",
       "299    MARKET           300     Text       200       0\n",
       "299       443           300  Numeric       601       1\n",
       "\n",
       "[1057 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Token ID'] = df1['Tokens'].map(word_to_id)\n",
    "\n",
    "df1['Tag ID'] = df1['Tag'].map(tag_to_id)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d93652",
   "metadata": {},
   "source": [
    "So we see here that **the classification problem becomes whether the token is numeric (positive), or the token is text-like (negative)**. We will now group this by the descriptor # (which we have judiciously preserved throughout our preprocessing steps). \n",
    "\n",
    "We will vectorize automatically by aggregating the entries into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8557a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chang\\AppData\\Local\\Temp\\ipykernel_47820\\1204781546.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df1_final = df1.groupby(['Descriptor #'], as_index = False)['Tokens', 'Tag', 'Token ID', 'Tag ID'].agg(lambda x: list(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descriptor #</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Token ID</th>\n",
       "      <th>Tag ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[DOLRTREE, 2257, 22574, ROSWELL]</td>\n",
       "      <td>[Text, Numeric, Numeric, Text]</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[AUTOZONE, 3547]</td>\n",
       "      <td>[Text, Numeric]</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[TGI, FRIDAYS, 1485, ]</td>\n",
       "      <td>[Text, Text, Numeric, Text]</td>\n",
       "      <td>[6, 7, 8, 9]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[BUFFALO, WILD, WINGS, 3]</td>\n",
       "      <td>[Text, Text, Text, Numeric]</td>\n",
       "      <td>[10, 11, 12, 13]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[J, CREW, 568, ]</td>\n",
       "      <td>[Text, Text, Numeric, Text]</td>\n",
       "      <td>[14, 15, 16, 9]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>296</td>\n",
       "      <td>[MCDONALD, S, F2151]</td>\n",
       "      <td>[Text, Text, Numeric]</td>\n",
       "      <td>[60, 61, 594]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>[NST, BEST, BUY, 1403, 332411]</td>\n",
       "      <td>[Text, Text, Text, Numeric, Numeric]</td>\n",
       "      <td>[76, 77, 78, 595, 596]</td>\n",
       "      <td>[0, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>[CVS, PHARMACY, 6689]</td>\n",
       "      <td>[Text, Text, Numeric]</td>\n",
       "      <td>[180, 181, 597]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>[BANANA, REPUBLIC, 8109]</td>\n",
       "      <td>[Text, Text, Numeric]</td>\n",
       "      <td>[598, 599, 600]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>[BOSTON, MARKET, 443]</td>\n",
       "      <td>[Text, Text, Numeric]</td>\n",
       "      <td>[199, 200, 601]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Descriptor #                            Tokens  \\\n",
       "0               1  [DOLRTREE, 2257, 22574, ROSWELL]   \n",
       "1               2                  [AUTOZONE, 3547]   \n",
       "2               3            [TGI, FRIDAYS, 1485, ]   \n",
       "3               4         [BUFFALO, WILD, WINGS, 3]   \n",
       "4               5                  [J, CREW, 568, ]   \n",
       "..            ...                               ...   \n",
       "295           296              [MCDONALD, S, F2151]   \n",
       "296           297    [NST, BEST, BUY, 1403, 332411]   \n",
       "297           298             [CVS, PHARMACY, 6689]   \n",
       "298           299          [BANANA, REPUBLIC, 8109]   \n",
       "299           300             [BOSTON, MARKET, 443]   \n",
       "\n",
       "                                      Tag                Token ID  \\\n",
       "0          [Text, Numeric, Numeric, Text]            [0, 1, 2, 3]   \n",
       "1                         [Text, Numeric]                  [4, 5]   \n",
       "2             [Text, Text, Numeric, Text]            [6, 7, 8, 9]   \n",
       "3             [Text, Text, Text, Numeric]        [10, 11, 12, 13]   \n",
       "4             [Text, Text, Numeric, Text]         [14, 15, 16, 9]   \n",
       "..                                    ...                     ...   \n",
       "295                 [Text, Text, Numeric]           [60, 61, 594]   \n",
       "296  [Text, Text, Text, Numeric, Numeric]  [76, 77, 78, 595, 596]   \n",
       "297                 [Text, Text, Numeric]         [180, 181, 597]   \n",
       "298                 [Text, Text, Numeric]         [598, 599, 600]   \n",
       "299                 [Text, Text, Numeric]         [199, 200, 601]   \n",
       "\n",
       "              Tag ID  \n",
       "0       [0, 1, 1, 0]  \n",
       "1             [0, 1]  \n",
       "2       [0, 0, 1, 0]  \n",
       "3       [0, 0, 0, 1]  \n",
       "4       [0, 0, 1, 0]  \n",
       "..               ...  \n",
       "295        [0, 0, 1]  \n",
       "296  [0, 0, 0, 1, 1]  \n",
       "297        [0, 0, 1]  \n",
       "298        [0, 0, 1]  \n",
       "299        [0, 0, 1]  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_final = df1.groupby(['Descriptor #'], as_index = False)['Tokens', 'Tag', 'Token ID', 'Tag ID'].agg(lambda x: list(x))\n",
    "\n",
    "df1_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650b15f",
   "metadata": {},
   "source": [
    "Machine learning models require standardized inputs, particularly with regards to input shape. We will need to pad the token ID and tag ID corresponding to each Descriptor before we do any computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba6ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum token length is 9.\n"
     ]
    }
   ],
   "source": [
    "li_token_len = []\n",
    "for token in df1_final['Token ID']:\n",
    "    li_token_len.append(len(token))\n",
    "\n",
    "max_token_len = max(li_token_len)\n",
    "print(f'The maximum token length is {max(li_token_len)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f50dd592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum tag length is 9.\n"
     ]
    }
   ],
   "source": [
    "li_tag_len = []\n",
    "for tag in df1_final['Tag ID']:\n",
    "    li_tag_len.append(len(tag))\n",
    "    \n",
    "print(f'The maximum tag length is {max(li_tag_len)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9ca41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec30e5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2, ...,   0,   0,   0],\n",
       "       [  4,   5,   0, ...,   0,   0,   0],\n",
       "       [  6,   7,   8, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [180, 181, 597, ...,   0,   0,   0],\n",
       "       [598, 599, 600, ...,   0,   0,   0],\n",
       "       [199, 200, 601, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tokens = pad_sequences(df1_final['Token ID'], maxlen = max_token_len, padding='post', value=0)\n",
    "pad_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e94326b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tag = pad_sequences(df1_final['Tag ID'], maxlen = max_token_len, padding='post', value=0)\n",
    "pad_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23be57",
   "metadata": {},
   "source": [
    "Check that the output of pad_tokens and pad_tag are not weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "492a46fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 9), (300, 9))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tokens.shape, pad_tag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4039a7",
   "metadata": {},
   "source": [
    "They are both uniform in shape. Let us check a few entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d257cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8734aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tag[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc890a",
   "metadata": {},
   "source": [
    "**Note: In our word dictionary (the encoding we did earlier to get these vectorizations), we have have padded with 0, the values corresponding to \"DOLRTREE\", which makes no sense, however, in terms of our computation, it makes sense to put a 0 there instead of a large non-zero value (it may actually skew the computations).** What matters is that since we padded with something marked as a \"Text\", it should automatically correspond to a label of \"Text\", which is exactly what we did.\n",
    "\n",
    "\n",
    "## Preprocess Our Vectors Even More\n",
    "\n",
    "We will now perform a little more preprocessing before we begin our training routine. We first one-hot encode the tags, so that every token will correspond to a one-hot encoded label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34abf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee9512fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be our y_true\n",
    "\n",
    "y_true = to_categorical(pad_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff54a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 9, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f763a6a3",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "Typically, we would use use train-test split from sklearn, or we could even code it ourselves, however, for this task, since the explicit training, validation, testing labels were given, we will just follow it. We did not shuffle any of our dataset, so we will just slice for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86d09bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our output label\n",
    "y_train, y_val, y_test = y_true[:100,:,:], y_true[100:200,:,:], y_true[200:300,:,:]\n",
    "\n",
    "x_train, x_val, x_test = pad_tokens[:100, :], pad_tokens[100:200, :], pad_tokens[200:300, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "733971b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21937dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd1299",
   "metadata": {},
   "source": [
    "## Model Building (Part 1)\n",
    "\n",
    "We will now build the classifier that will do this classification. We do not have that many data points to train this on, but let us build one from scratch anyways.\n",
    "\n",
    "The architecture we will be pursuing is a many-to-many LSTM RNN (takes in multiple inputs that have respective outputs).\n",
    "\n",
    "**Note:** This is a very common architecture for a named-entity recognition or a part of speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da1e8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(list(df1['Tokens'].unique())) + 1\n",
    "output_dim = 8\n",
    "input_length = max_token_len\n",
    "output_units = len(id_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83df9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimensions 603\n",
      "Output Dimension 8\n",
      "Input Length 9\n",
      "Output Units 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Input Dimensions {input_dim}')\n",
    "print(f'Output Dimension {output_dim}')\n",
    "print(f'Input Length {max_token_len}')\n",
    "print(f'Output Units {output_units}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6a8dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary things\n",
    "\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45cc7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all layers to put into model\n",
    "li_layers = [\n",
    "    Input(shape=(max_token_len,)),\n",
    "    Embedding(input_dim=input_dim, output_dim=output_dim),\n",
    "    Bidirectional(LSTM(units=output_dim, return_sequences=True, name='LSTM1')),\n",
    "    LSTM(units=output_dim, return_sequences=True, name='LSTM2'),\n",
    "    TimeDistributed(Dense(units=output_units, activation='softmax'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9646739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 9, 8)              4824      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 9, 16)            1088      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 9, 8)              800       \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 9, 2)             18        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,730\n",
      "Trainable params: 6,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential(li_layers)\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aed5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate logits = true as we do not generate a probability measure on our output\n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(), \n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.FalsePositives(name='FP'),\n",
    "                       tf.keras.metrics.FalseNegatives(name='FN')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbc39a",
   "metadata": {},
   "source": [
    "## Fit our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70f6d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch number\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "742ba468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 7s 101ms/step - loss: 0.6806 - categorical_accuracy: 0.8556 - precision: 0.8556 - recall: 0.8556 - FP: 130.0000 - FN: 130.0000 - val_loss: 0.6670 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6500 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.6316 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6036 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.5733 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5267 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.4803 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4273 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3939 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3692 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3684 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.3558 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3623 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.3495 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3561 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3438 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3509 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.3385 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3461 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.3337 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3417 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.3293 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3375 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.3246 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3337 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3204 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3300 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3165 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3266 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.3128 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3235 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.3095 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3205 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.3063 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3178 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.3032 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3151 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3002 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3125 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.2972 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3100 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.2942 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3075 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.2913 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3051 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2883 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3026 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.2852 - categorical_accuracy: 0.8689 - precision: 0.8689 - recall: 0.8689 - FP: 118.0000 - FN: 118.0000 - val_loss: 0.3004 - val_categorical_accuracy: 0.8600 - val_precision: 0.8600 - val_recall: 0.8600 - val_FP: 126.0000 - val_FN: 126.0000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "history_1 = model1.fit(x_train, y_train,batch_size=5,epochs=epochs,\n",
    "                      validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "378858ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = np.argmax(model1.predict(x_train), axis=2)\n",
    "\n",
    "y_train_classes = np.argmax(y_train,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd2bc7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81e8531f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc3da305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Text       0.87      1.00      0.93       782\n",
      "     Numeric       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.87       900\n",
      "   macro avg       0.43      0.50      0.46       900\n",
      "weighted avg       0.75      0.87      0.81       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_classes.flatten(), y_pred_train.flatten(), target_names=id_to_tag.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932be91f",
   "metadata": {},
   "source": [
    "## Evaluate Our Model\n",
    "\n",
    "Now upon first sight, our accuracy metrics look extremely good. But is it legitimate? Let us take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a68505f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Numeric</th>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag ID\n",
       "Tag            \n",
       "Numeric     372\n",
       "Text        685"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = df1.groupby('Tag').count()[['Tag ID']]\n",
    "\n",
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4bf86",
   "metadata": {},
   "source": [
    "So we see that this is almost a 65-35 split of Text-Numeric tags. Thus, this dataset is very imbalanced! We can only judge the performance of this classification by looking at various metrics (precision, recall, f1), accuracy is not meaningful here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfaa1d3",
   "metadata": {},
   "source": [
    "We can get the actual ground truth per class by taking the argmin along the possible classes. Because we one-hot encoded it, only the class corresponding to the label will have a 1 (everything else 0), hence, we can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fba71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground truth\n",
    "\n",
    "y_true = np.argmax(y_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "35130fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "\n",
    "y_hat = model1.predict(x_train)\n",
    "\n",
    "y_pred = np.argmax(y_hat, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cee29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten vectors to compare outputs\n",
    "\n",
    "y_true_flat = y_true.flatten()\n",
    "\n",
    "y_pred_flat = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0921a122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Text       0.86      1.00      0.92       772\n",
      "     Numeric       0.00      0.00      0.00       128\n",
      "\n",
      "    accuracy                           0.86       900\n",
      "   macro avg       0.43      0.50      0.46       900\n",
      "weighted avg       0.74      0.86      0.79       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get classification report\n",
    "\n",
    "dict_class_report = classification_report(y_true_flat, y_pred_flat, target_names = id_to_tag.values())\n",
    "\n",
    "print(classification_report(y_true_flat, y_pred_flat, target_names = id_to_tag.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29da5fb5",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "We must discuss what occurred here. Our biggest issue here is how imbalanced our dataset is (we can look at the support in the classification report, it was close to an 85-15 split of \"Not Numbers\" vs \"Numbers\" for our classes). Furthermore, even if our dataset *were* balanced, this model would likely still not perform up to what would be needed for a task like this. In such a task as this one, we would **ideally** want a precision/recall closer to 80%-90%, as to minimize the amount of work needed to correct the mistagged labels (this is a task where we must absolutely get the correct labels).\n",
    "\n",
    "Given the limited data we have, using a freshly-instantiated neural network is not an optimal way to approach this task because even for a neural network *as shallow as this one*, we have over 6000 parameters to train from scratch. With the limited data that we have (exactly 100 training samples), it cannot be expected that our neural network will find the right weights to inference properly.\n",
    "\n",
    "## Pros of LSTM RNN\n",
    "\n",
    "- Easy to preprocess data and train it; the training process and preprocessing the text to an input suitable for a neural network was not difficult at all\n",
    "- Simple to translate the business problem to a technical implementation\n",
    "\n",
    "## Cons of LSTM RNN\n",
    "\n",
    "- Lots of moving parts; i.e. we have too many parameters for even the simplest models\n",
    "- For something with a lot of moving parts, we do not have nearly enough data to train all of these parameters properly\n",
    "- Given the above notes, this will absolutely fail the edge cases unless we give it more data, and plenty of representative samples of many cases; in this problem, this is simply not a luxury that we have\n",
    "\n",
    "# 3) spaCy's *Embed, Encode, Attend, Predict* Model\n",
    "\n",
    "Here, we will explore a Natural Language Processing library called **spaCy**. This library is ubiquitous for its *embed, encode, attend, predict* architecture, and its convenient workflow. To illustrate what the architecture of the model is like, we give the following slide discussing this workflow (link: https://github.com/explosion/talks/blob/master/2018-04-12_Embed-Encode-Attend-Predict.pdf):\n",
    "\n",
    "\n",
    "## How We Will Use This\n",
    "\n",
    "We will use a blank model from spaCy, and in particular, we will use the **named entity recognition** pipeline in the model (the models also have other possible pipelines for other applications). We are trying to do, what is essentially, *transfer learning*, i.e. taking a pre-(trained/built) model and then adapting the model specifically for our task. \n",
    "\n",
    "Our workflow that we will demonstrate is the typical workflow: \n",
    "\n",
    "- Preprocess Data (cleaning, reshaping for input into model)\n",
    "- Set up the model configuration files\n",
    "- Train the model, and score it on the validation set during training\n",
    "- Inference it on test data\n",
    "- Evaluate the metrics and evaluate where the model fails\n",
    "\n",
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c4bbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Chang\\Desktop\\Work Things\\Internships\\Affinity Solutions\\Summer Internship - Homework Exercise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97391c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean awkward spaces\n",
    "def clean_spaces(s):\n",
    "    return re.sub(' +', ' ', s)\n",
    "\n",
    "# split on punctuations because the vectorizer will not understand any number with it\n",
    "def split_punc(s):\n",
    "    return re.sub(r'([^\\w\\s]|_)',' ',s)\n",
    "\n",
    "# take out any numbers with zeros leading and trailing it\n",
    "def split_leading_zeros(s):\n",
    "    return re.sub(r'\\b0+', '', s)\n",
    "\n",
    "# split numbers from words\n",
    "\n",
    "def split_num_from_word(s):\n",
    "    li_split = s.split(' ')\n",
    "    li_where_to_split = []\n",
    "    start_, end_ = 0, 0\n",
    "    for ind, item in enumerate(li_split):\n",
    "        # filter out for words with both letters and numbers\n",
    "        if not item.isalpha() and item.isalnum():\n",
    "            split_num_word = re.split('(\\d+)', item)\n",
    "            if len(split_num_word[-1]) > 2 or len(split_num_word[0]) > 2:\n",
    "                start_, end_ = (s.index(split_num_word[1])), s.index(split_num_word[1]) + len(split_num_word[1])\n",
    "\n",
    "    return s[:start_] + ' ' + s[start_:end_] + ' ' + s[end_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c564ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply data cleaning we did above\n",
    "\n",
    "transaction_descriptor = df['transaction_descriptor']\n",
    "\n",
    "df['transaction_descriptor'] = list(map(clean_spaces, map(split_leading_zeros, map(split_num_from_word, map(split_punc, transaction_descriptor)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ea71c",
   "metadata": {},
   "source": [
    "## Load a spaCy model\n",
    "\n",
    "Let us see how this model will output before we go into the nitty gritty of training and inferencing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72d59769",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_init = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8fd5465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 'CARDINAL'),\n",
       " ('CREW', 'ORG'),\n",
       " ('40', 'CARDINAL'),\n",
       " ('GREENVILLE SC', 'ORG'),\n",
       " ('FIVE', 'CARDINAL')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions on initial run\n",
    "li_init_predictions = []\n",
    "for descriptor in df['transaction_descriptor']:\n",
    "    doc = nlp_init(descriptor)\n",
    "    for ent in doc.ents:\n",
    "        li_init_predictions.append((ent.text, ent.label_))\n",
    "        \n",
    "li_init_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19b486",
   "metadata": {},
   "source": [
    "To illustrate this pre-trained model's many pipelines, we can display it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4c26be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get components of the pipeline\n",
    "\n",
    "nlp_init.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f79b57a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US GPE\n",
      "5009 DATE\n"
     ]
    }
   ],
   "source": [
    "# run a toy example\n",
    "\n",
    "# example on an entry that we could possible have\n",
    "\n",
    "ex1 = 'TOYS R US 5009'\n",
    "\n",
    "doc = nlp_init(ex1)\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790b261",
   "metadata": {},
   "source": [
    "So we see that our nlp pipeline from spacy requires a lot of training for our specific examples. It does not have the exact domain-specific knowledge that we need it to have for our task (in particular, it does not have the ability to discern between stores and numbers).\n",
    "\n",
    "## Train Our Model\n",
    "\n",
    "We will feed our training set into the model.\n",
    "\n",
    "Training data must be presented to spacy nlp models in the form:\n",
    "\n",
    "[(Text to train on, {'entities': (start index, stop index, 'desired label')]\n",
    "\n",
    "**Get our training data into this format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47fc0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get our data into above format\n",
    "\n",
    "def load_spacy_data(train_df, dataset):\n",
    "    # load data\n",
    "    train_df = df.loc[df['dataset'] == dataset]\n",
    "\n",
    "    # get into form we need to train spacy model\n",
    "    li_data = []\n",
    "    for store_num, descriptor in zip(train_df['store_number'], train_df['transaction_descriptor']):\n",
    "        start_pos = descriptor.index(store_num)\n",
    "        end_pos = start_pos + len(store_num)\n",
    "        li_data.append((descriptor, {'entities':[(start_pos, end_pos, 'store_num')]}))\n",
    "\n",
    "    return li_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4325d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_spacy_data(df.loc[df['dataset'] == 'train'], 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6393b",
   "metadata": {},
   "source": [
    "### Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6eaaaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = load_spacy_data(df.loc[df['dataset'] == 'validation'], 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1c98109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 100 training entries.\n",
      "We have 100 validation entries.\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(train_data)} training entries.')\n",
    "\n",
    "print(f'We have {len(val_data)} validation entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84395b14",
   "metadata": {},
   "source": [
    "### Load a Blank Model\n",
    "\n",
    "We will train a blank model (the one we loaded earlier was a pretrained model) to see what baseline results we could obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003bed8d",
   "metadata": {},
   "source": [
    "### Load Data into Proper File Format\n",
    "\n",
    "Unlike many of the other machine learning libraries, spaCy models (to my knowledge as of version 3.2) cannot be trained directly through python script. We must load our above training and validation data into a serialized file format, the **.spacy** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36918023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dot_spacy(data, dataset, nlp):\n",
    "    db = DocBin() # create a DocBin object\n",
    "    for text, annot in tqdm(data): # data in previous format\n",
    "        doc = nlp.make_doc(text) # create doc object from text\n",
    "        ents = []\n",
    "        for start, end, label in annot['entities']: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode='contract')\n",
    "            if span is None:\n",
    "                print('Skipping entity')\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        try:\n",
    "            doc.ents = ents # label the text with the ents\n",
    "            db.add(doc)\n",
    "        except:\n",
    "            print(text, annot)\n",
    "    db.to_disk('./' + dataset + '.spacy') # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a33739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will store files named \"train.spacy\" and \"dev.spacy\" in our directory with this notebook, we will feed this into\n",
    "# our config file\n",
    "\n",
    "load_dot_spacy(train_data, 'train', nlp)\n",
    "\n",
    "load_dot_spacy(val_data, 'dev', nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183351fe",
   "metadata": {},
   "source": [
    "### Get the Config File\n",
    "\n",
    "For spacy 3.x, we must call our training protocol in a config file. We will run the spacy training loop from the command prompt instead of directly from python.\n",
    "\n",
    "See documentation: https://spacy.io/usage/training\n",
    "\n",
    "### Instructions to get the config file + autofill the config file\n",
    "\n",
    "- Activate virtual environment of the project (must have spaCy installed)\n",
    "\n",
    "- Type in \"python -m spacy init fill-config base_config.cfg config.cfg\" to the command prompt\n",
    "\n",
    "- Run it\n",
    "\n",
    "We will obtain a config file, named \"config.cfg\".\n",
    "\n",
    "### Instructions to run the training loop\n",
    "\n",
    "Go into the command prompt, and type in:\n",
    "\n",
    "\"python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy\"\n",
    "\n",
    "Then run it. It will train, and as it trains, it will display the metrics.\n",
    "\n",
    "## Evaluate the Performance of Our Model\n",
    "\n",
    "We will now evaluate the performance of our model on our testing data.\n",
    "\n",
    "First load the model that we trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "172fbf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_best = spacy.load('./output/model-best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5476932",
   "metadata": {},
   "source": [
    "Load the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c306c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_spacy_data(df.loc[df['dataset']=='test'], dataset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333400c",
   "metadata": {},
   "source": [
    "### Some Informal Testing\n",
    "\n",
    "Let us test entry-by-entry first, to make sure that we are getting reasonable outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3793b2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' IN N OUT BURGER 242', {'entities': [(17, 20, 'store_num')]})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = test_data[0]\n",
    "\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "373468ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 store_num\n"
     ]
    }
   ],
   "source": [
    "# apply the model to the text of our first test data\n",
    "\n",
    "test1_doc = nlp_best(test_1[0])\n",
    "\n",
    "for ent in test1_doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e297730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BP 9442088 LIBERTYVILLE B', {'entities': [(3, 10, 'store_num')]})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = test_data[1]\n",
    "\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e50ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9442088 store_num\n"
     ]
    }
   ],
   "source": [
    "test2_doc = nlp_best(test_2[0])\n",
    "\n",
    "if len(test2_doc.ents) == 0:\n",
    "    li1.append('False')\n",
    "for ent in test2_doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3801f61",
   "metadata": {},
   "source": [
    "**Note:** The data cleaning we did earlier was extremely helpful because originally, this entry had \"9442088LIBERTYVILLE\", which would've made the store number indistinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79bd8540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' LBOUTLETS 4249 1475 N BUR', {'entities': [(11, 15, 'store_num')]})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = test_data[7]\n",
    "\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e7f8eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4249', 'store_num')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3_doc = nlp_best(test_3[0])\n",
    "li1 = []\n",
    "for ent in test3_doc.ents:\n",
    "    if len(test3_doc.ents) == 0:\n",
    "        li1.append('False')\n",
    "    else:\n",
    "        li1.append((ent.text, ent.label_))\n",
    "li1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c26baa",
   "metadata": {},
   "source": [
    "**This is an interesting case that shows us the strength of this model**. In cases where there are multiple numbers, this **model seems to be able to tell the difference between the numbers**. \n",
    "\n",
    "For example, in our example just now, we had the descriptor:\n",
    "\n",
    "\"LBOUTLETS 4249 1475 N BUR\"\n",
    "\n",
    "Our model was able to recognize that **4249** was preceded by a store or organization, and that **1475** was simply the number that came before an address.\n",
    "\n",
    "### Testing\n",
    "\n",
    "Let us inference our model on our entire testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb41b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for quick testing\n",
    "# test_data - of the form generated by load_spacy_data function\n",
    "\n",
    "def test_ner(test_data, model):\n",
    "    li_inference_results = []\n",
    "    # iterate through texts and apply model\n",
    "    for ind, (text, annotations) in enumerate(test_data):\n",
    "        doc_test = model(text)\n",
    "        \n",
    "        # if the model doesn't predict anything, throw a blank output into the list\n",
    "        # otherwise append the prediction + label\n",
    "        if len(doc_test.ents) == 0:\n",
    "            \n",
    "            # we can hardcode 'store_num' as label because we're only looking for store_num labels\n",
    "            li_inference_results.append((ind,'', 'store_num',len(doc_test.ents)))\n",
    "        else:\n",
    "            for ent in doc_test.ents:\n",
    "                li_inference_results.append((ind, text, ent.text, ent.label_, len(doc_test.ents)))\n",
    "    return li_inference_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ff389",
   "metadata": {},
   "source": [
    "The output of our model is of the form:\n",
    "\n",
    "(the input index that the label corresponds to, the input (descriptor), the prediction (store number), label ('store_num'), numbers of predictions that the model made for the descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94cd408c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ' IN N OUT BURGER 242', '242', 'store_num', 1),\n",
       " (1, 'BP 9442088 LIBERTYVILLE B', '9442088', 'store_num', 1),\n",
       " (2, ' JCPENNEY 1419', '1419', 'store_num', 1),\n",
       " (3, ' ROSS STORES 1019', '1019', 'store_num', 1),\n",
       " (4, ' WM SUPERCENTER 38', '38', 'store_num', 1),\n",
       " (5, ' TUESDAY MORNING 673 6', '673', 'store_num', 1),\n",
       " (6, ' IHOP 629 WHITE HOUSE TN', '629', 'store_num', 1),\n",
       " (7, ' LBOUTLETS 4249 1475 N BUR', '4249', 'store_num', 1),\n",
       " (8, ' WINN DIXIE 2505 VALRICO FL 3454 ', '2505', 'store_num', 2),\n",
       " (8, ' WINN DIXIE 2505 VALRICO FL 3454 ', '3454', 'store_num', 2),\n",
       " (9, ' BURLINGTON STORES 825', '825', 'store_num', 1),\n",
       " (10, ' WM SUPERCENTER 2923', '2923', 'store_num', 1),\n",
       " (11, ' BUFFALO WILD WINGS 58 CARSON CITY NV', '58', 'store_num', 1),\n",
       " (12, ' BOB EVANS REST 2039', '2039', 'store_num', 1),\n",
       " (13, ' JIMMY JOHNS 382 E', '382', 'store_num', 1),\n",
       " (14, ' PENSKE TRK LSG 12260', '12260', 'store_num', 1),\n",
       " (15, ' AEROPOSTALE 864', '864', 'store_num', 1),\n",
       " (16, ' GIANT 338', '338', 'store_num', 1),\n",
       " (17, ' DOLLAR GENERAL DG 11', '11', 'store_num', 1),\n",
       " (18, ' NNT ITS FASHION 70360265', '70360265', 'store_num', 1),\n",
       " (19, ' BIG LOTS STORES 4393 ', '4393', 'store_num', 1),\n",
       " (20, ' AT T SPRING MOBILE 62', '62', 'store_num', 1),\n",
       " (21, ' OLD NAVY US 7212', '7212', 'store_num', 1),\n",
       " (22, ' BP 8644346ES 30 B96', '8644346ES', 'store_num', 2),\n",
       " (22, ' BP 8644346ES 30 B96', '30', 'store_num', 2),\n",
       " (23, 'NNT POLO RL WRENTHA 130571 ', '130571', 'store_num', 1),\n",
       " (24, ' CHAMPS 14178', '14178', 'store_num', 1),\n",
       " (25, ' CNS GUESS 3220 282163', '3220', 'store_num', 1),\n",
       " (26, ' HOMEGOODS 407', '407', 'store_num', 1),\n",
       " (27, ' DOLLAR GENERAL 14', '14', 'store_num', 1)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_output = test_ner(test_data, nlp_best)\n",
    "\n",
    "inference_output[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c21b39ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has made 107 predictions.\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has made {len(inference_output)} predictions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01c3ea",
   "metadata": {},
   "source": [
    "**Note:** The model made more predictions than inputs because for descriptors where it identified more than 1 store number, the model outputs all of them! This is an advantage that we have (and this is similar to what we were looking to achieve earlier in *part 2*, albeit with more success here).\n",
    "\n",
    "Let us check which predictions the model was \"indecisive\" on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b64dc6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The descriptor at entry 8 is  WINN DIXIE 2505 VALRICO FL 3454 \n",
      "The predicted store number for entry 8 is 2505\n",
      "\n",
      "The descriptor at entry 8 is  WINN DIXIE 2505 VALRICO FL 3454 \n",
      "The predicted store number for entry 8 is 3454\n",
      "\n",
      "The descriptor at entry 22 is  BP 8644346ES 30 B96\n",
      "The predicted store number for entry 22 is 8644346ES\n",
      "\n",
      "The descriptor at entry 22 is  BP 8644346ES 30 B96\n",
      "The predicted store number for entry 22 is 30\n",
      "\n",
      "The descriptor at entry 28 is  WINN DIXIE 2454 SEFFNER FL 1033 \n",
      "The predicted store number for entry 28 is 2454\n",
      "\n",
      "The descriptor at entry 28 is  WINN DIXIE 2454 SEFFNER FL 1033 \n",
      "The predicted store number for entry 28 is 1033\n",
      "\n",
      "The descriptor at entry 33 is  NAVY EXCHANGE 50161 3\n",
      "The predicted store number for entry 33 is 50161\n",
      "\n",
      "The descriptor at entry 33 is  NAVY EXCHANGE 50161 3\n",
      "The predicted store number for entry 33 is 3\n",
      "\n",
      "The descriptor at entry 36 is  CASEYS GEN STORE 2597 SLOAN IA51055\n",
      "The predicted store number for entry 36 is 2597\n",
      "\n",
      "The descriptor at entry 36 is  CASEYS GEN STORE 2597 SLOAN IA51055\n",
      "The predicted store number for entry 36 is IA51055\n",
      "\n",
      "The descriptor at entry 42 is  NST BEST BUY 48 72393\n",
      "The predicted store number for entry 42 is 48\n",
      "\n",
      "The descriptor at entry 42 is  NST BEST BUY 48 72393\n",
      "The predicted store number for entry 42 is 72393\n",
      "\n",
      "The descriptor at entry 72 is  FOOTACTION 57331 TAMPA FL 2340 \n",
      "The predicted store number for entry 72 is 57331\n",
      "\n",
      "The descriptor at entry 72 is  FOOTACTION 57331 TAMPA FL 2340 \n",
      "The predicted store number for entry 72 is 2340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, descriptor, prediction, _, len_ in inference_output:\n",
    "    if len_ != 1:\n",
    "        print(f'The descriptor at entry {index} is {descriptor}')\n",
    "        print(f'The predicted store number for entry {index} is {prediction}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b331f",
   "metadata": {},
   "source": [
    "As we see here, our model still gets hung up on entries where there is a number present in the descriptor (especially numbers in addresses). Numbers next to addresses are a particular weakness, because our model can deduce context, and because locations (like \"TAMPA FL\") are nouns, **the model likely cannot make a definitive decision** on whether a number (2340) following a location (TAMPA FL) **is actually a store number of an address number**. Something **we could do** to go further  would be to **feed additional labels** that actually make a difference between **address numbers and store numbers**.\n",
    "\n",
    "### Score our Model on Our Testing Set\n",
    "\n",
    "We will score the model on two criteria:\n",
    "\n",
    "- Accuracy: Out of all of the ground truths (so the 100 store number labels corresponding to descriptors), how many of them did the model predict correctly? (if the **model predicted more than 1 label for an input**, we will regard it as **incorrect**)\n",
    "\n",
    "- Precision: Out of all of the model's predictions (so the 107 predictions that were outputted above), how many of those were correct?\n",
    "\n",
    "**Note: Precision and Recall is typically used in classification, where we evaluate the precision and recall corresponding to each output class, but we are not predicting classes here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0d74645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(inference_output, ground_truth_df, return_not_matched=False):\n",
    "    metrics_dict = dict()\n",
    "    not_matched = []\n",
    "    # initialize number correct, number that model matched\n",
    "    num_correct, num_matched = 0, 0\n",
    "    for _, descriptor, prediction, _, num_predictions in inference_output:\n",
    "        eval_row = ground_truth_df.loc[ground_truth_df['transaction_descriptor'] == descriptor]['store_number']\n",
    "        \n",
    "        # the prediction is matched if it matches the store_num value of the ground truth for the descriptor\n",
    "        if eval_row.values[0] == prediction:\n",
    "            num_matched += 1\n",
    "            \n",
    "            # the prediction can be CORRECT only if the store_num matches, and the model only took 1 attempt\n",
    "            if num_predictions == 1:\n",
    "                num_correct += 1\n",
    "        else:\n",
    "            not_matched.append((descriptor, prediction, num_predictions))\n",
    "    \n",
    "    metrics_dict['accuracy'] = num_correct / ground_truth_df.shape[0]\n",
    "    metrics_dict['precision'] = num_matched / len(inference_output)\n",
    "    if not return_not_matched:\n",
    "        return metrics_dict\n",
    "    else:\n",
    "        return metrics_dict, not_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68aa916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model accuracy is 90.000%\n",
      "Our model precision is 89.720%\n"
     ]
    }
   ],
   "source": [
    "test_df = df.loc[df['dataset'] == 'test']\n",
    "metrics = score_model(inference_output, test_df)\n",
    "\n",
    "accuracy_model, precision_model = metrics['accuracy'], metrics['precision']\n",
    "print(f'Our model accuracy is {accuracy_model*100:.3f}%')\n",
    "print(f'Our model precision is {precision_model*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccba40",
   "metadata": {},
   "source": [
    "## Failure Analysis\n",
    "\n",
    "**Let's examine the entries that our model got wrong**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c182415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' WINN DIXIE 2505 VALRICO FL 3454 ', '3454', 2),\n",
       " (' BP 8644346ES 30 B96', '8644346ES', 2),\n",
       " (' BP 8644346ES 30 B96', '30', 2),\n",
       " ('NNT POLO RL WRENTHA 130571 ', '130571', 1),\n",
       " (' WINN DIXIE 2454 SEFFNER FL 1033 ', '1033', 2),\n",
       " (' NNT SEARS HOMETOWN 862751', '862751', 1),\n",
       " (' NAVY EXCHANGE 50161 3', '3', 2),\n",
       " (' CASEYS GEN STORE 2597 SLOAN IA51055', 'IA51055', 2),\n",
       " (' NST BEST BUY 48 72393', '72393', 2),\n",
       " (' FOOTACTION 57331 TAMPA FL 2340 ', '2340', 2),\n",
       " (' SUBWAY 32128', '32128', 1)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, not_matched = score_model(inference_output, test_df, return_not_matched=True)\n",
    "\n",
    "not_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a867bc",
   "metadata": {},
   "source": [
    "### Take a Deep Look at Some Cases\n",
    "\n",
    "1) Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e77bd5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_descriptor</th>\n",
       "      <th>store_number</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NNT POLO RL WRENTHA 130571</td>\n",
       "      <td>13057</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_descriptor store_number dataset\n",
       "223  NNT POLO RL WRENTHA 130571         13057    test"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['transaction_descriptor'] == 'NNT POLO RL WRENTHA 130571 ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c3ef4",
   "metadata": {},
   "source": [
    "We see that this one is an unfortunate error, there is no way of knowing, without knowing the label itself beforehand, that we were not supposed to keep the 1 at the end.\n",
    "\n",
    "2) Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ead4bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_descriptor</th>\n",
       "      <th>store_number</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>BP 8644346ES 30 B96</td>\n",
       "      <td>8644346</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transaction_descriptor store_number dataset\n",
       "222    BP 8644346ES 30 B96      8644346    test"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['transaction_descriptor'] == ' BP 8644346ES 30 B96']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6643c0",
   "metadata": {},
   "source": [
    "This is also a confusing case because there were 3 separate alphanumeric fields that could've been interpreted as a \"store number\". This is especially true since it is ambiguous as to what \"BP\" is. A lot of the other descriptors had full names, or had longer entries for the store names in the descriptors, so the model was likely able to deduce the context in those cases. \n",
    "\n",
    "3) Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03e13258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_descriptor</th>\n",
       "      <th>store_number</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NNT SEARS HOMETOWN 862751</td>\n",
       "      <td>8627</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         transaction_descriptor store_number dataset\n",
       "231   NNT SEARS HOMETOWN 862751         8627    test"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['transaction_descriptor'] == ' NNT SEARS HOMETOWN 862751']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933a423",
   "metadata": {},
   "source": [
    "We see that, just like case 1, this is just an unfortunate case of the descriptor itself being unclear. It is arguable as to whether a human, analyzing this one by one, could extract this correctly.\n",
    "\n",
    "4) Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ff6cbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_descriptor</th>\n",
       "      <th>store_number</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>SUBWAY 32128</td>\n",
       "      <td>3212</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transaction_descriptor store_number dataset\n",
       "292           SUBWAY 32128         3212    test"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['transaction_descriptor'] == ' SUBWAY 32128']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134d550",
   "metadata": {},
   "source": [
    "Case 4 is similar to Case 3 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb207b",
   "metadata": {},
   "source": [
    "5) Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "764e9164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_descriptor</th>\n",
       "      <th>store_number</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>CASEYS GEN STORE 2597 SLOAN IA51055</td>\n",
       "      <td>2597</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   transaction_descriptor store_number dataset\n",
       "236   CASEYS GEN STORE 2597 SLOAN IA51055         2597    test"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['transaction_descriptor'] == ' CASEYS GEN STORE 2597 SLOAN IA51055']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081cacc",
   "metadata": {},
   "source": [
    "To comment on this case, the model was exposed to a few store numbers that were a combination of letters and numbers. The model likely got this wrong because the \"IA51055\" was likely supposed to be \"IA 51055\", and that the store number could've looked like a street address, given that a lot of the other street addresses present in the validation and training set were formatted like this.\n",
    "\n",
    "## Pros of spaCy NLP Model\n",
    "\n",
    "- Scalable\n",
    "- Simple to Train\n",
    "- Very Good Performance Despite Limited Dataset\n",
    "- Despite small amount of data, handles *some* hard edge cases\n",
    "\n",
    "## Cons of spaCy NLP Model\n",
    "\n",
    "- Fails some edge cases (this is rather nitpicky however, even humans may have not extracted those properly)\n",
    "\n",
    "## What to do Next?\n",
    "\n",
    "We could **possibly explore hyperparameter tuning or transfer learning with an existing model** that is trained extensively (spaCy has a few of those available for download). However, I assess that *this is not necessary* because:\n",
    "\n",
    "1) We achieved about 90% in both accuracy and precision with our model, from a blank instance of spaCy's model architecture. Some of the **edge cases are unresolvable** unless we know, beforehand, the labels of the testing data. And while we have access to them here, in practice, we should not be looking at testing data because we don't have the luxury of tagged/labeled testing data! We could possibly improve our loss or accuracy by a little bit, but many of these edge cases (shown in the preceding section) are hard for **even humans** to extract the store number, unless we know the labels apriori.\n",
    "\n",
    "2) Likewise, hyperparameter tuning will not be useful for the same reasons as stated before. The last few test entries present a challenge for even humans, no amount of improvement will likely be able to predict all of those.\n",
    "\n",
    "**The best way to improve this model** is to **give it more data**. The more that this model has to learn off of, the more it can adapt to difficult edge cases (like the *numbers in addresses*, or the *store numbers that are concatenated with other numbers*). It is important that we not only give it *more* data, but that we give it *more variety* of data. The **more different cases that our model is exposed to, the better it will generalize**.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Perspective to Carry in a Project\n",
    "\n",
    "In any machine learning/data science project, there are always two aspects of the problem:\n",
    "\n",
    "1) **The business/practical problem**\n",
    "\n",
    "This is the statement of the problem that deals with the implications of achieving a certain task, and why we feel that machine learning/data science techniques will help us in accomplishing this task, particularly in a manner that exceeds the ability of humans in some way (either efficiency, accuracy, scalability, etc.)\n",
    "\n",
    "2) **The technical problem**\n",
    "\n",
    "This is the statement of the problem that deals with the *why* and the *how*. *How* do we leverage technical resources to accomplish this task? *Why* does our methodology and technique(s) work? Furthermore, we must be careful to acknowledge any practical considerations (like resource limitations, time limitations, etc.)\n",
    "\n",
    "### Our Task\n",
    "\n",
    "In this perspective, the **business/practical problem** of this task is to extract information (store numbers) out of a list of businesses/organizations. The implication of this is that this exceeds the effiency that humans would be able to accomplish this task with, and a single model built here is scalable to thousands, and even millions, of entries.\n",
    "\n",
    "The **technical problem** of this task (what we are really focused on here) is how we extract this information. More specifically, how do we deal with text data and what must we do to ensure that our models are able to give clean predictions? \n",
    "\n",
    "**To answer the latter question**, **I explored 3 ways** we could possibly deal with the text data, and how to extract our desired information from it:\n",
    "\n",
    "1) Filtering with Regular Expressions and Typical String Parsing Methods\n",
    "\n",
    "2) Building an LSTM RNN\n",
    "\n",
    "3) Training a Blank Instance of a Dedicated, Multi-purpose Natural Language Processing Model\n",
    "\n",
    "After a lot of experimentation and observations of the pros and cons of each method, we have a clear winner with regards to which method is the best to handle this specific problem. The criteria for a good model/method here was the following:\n",
    "\n",
    "- Scalable and Generalizable\n",
    "- Easy to Implement\n",
    "- Can overcome the limitations surrounding the problem (namely our lack of data)\n",
    "\n",
    "**Option 1** was easy to implement, and clearly was not made any less useful by our lack of data (in fact, the less data there is, the easier it is). However, it is clearly not scalable and generalizable because of the nature of regular expressions. We could easily enumerate every case possible for the limited sample we had (*300 entries*), but clearly, if we scale our data up more, and throw in slight variations of existing cases, the amount of regular expression queries we have to write become out of control.\n",
    "\n",
    "**Option 2** is scalable and generalizable (in a technical sense, just by nature of what neural networks are), and it is also easy to implement (this is subjective too, but TensorFlow is far simpler than writing hundreds of regular expression queries), but it was clearly hampered by the limitations in our data. Neural networks, as a general rule of thumb, require a lot of data to be effective due to the sheer amount of parameters that must be trained and updated. Furthermore, for a simple implementation, we had to restate our problem to a strict 2-class classification problem. This, in itself, brought more issues (caused imbalanced data) which further reduced the effectiveness of this approach given the limitations.\n",
    "\n",
    "**Option 3** is scalable and generalizable (with more data), it is easy to implement, and because the model architecture was already laid out, we could just adapt it to our specific problem. Training this model was surprisingly effective in helping it learn our specific task, even despite the small amount of data that we had. There is no doubt that, with more varied data, this model would be extremely accurate.\n",
    "\n",
    "In conclusion, we see that spaCy's *Embed, Encode, Attend, Predict* model is significantly more reliable than a traditional RNN (even with the many-to-many LSTM architecture), and it is significantly more scalable than a non-machine learning approach. From a blank model instance, we obtained an **accuracy of 90.00%**, and a **precision of 89.72%**! Although these results are not optimal (we would like to see higher accuracies if possible), we also have to note that our training, validation, testing samples were limited in both size (*100 samples each*), and scope of edge cases, for our model to learn sufficiently (*refer to part 2*). This model exceeded personal expectations. \n",
    "\n",
    "Furthermore, in our analysis of the failed cases, we see that they were instances that would have been extremely difficult to predict **without having apriori knowledge** about the true store numbers (look at *Case 1, 3, 4 in our failure analysis*). Another advantage of using this model is that, in the event that the model is unsure of the label, it actually predicted two labels. This is advantageous to us because in many machine learning workflows/cycles, it is still necessary to do further post-processing of model outputs, and if model actually has multiple options for guesses, we can always choose the correct ones, or simply filter out the incorrect ones with additional models, or with other criteria based on context.\n",
    "\n",
    "**For the future...** we can explore more hyperparameter tuning and transfer learning, given that we have access to more data..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blank_env",
   "language": "python",
   "name": "blank_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
